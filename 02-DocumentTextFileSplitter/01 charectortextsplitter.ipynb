{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a361f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: ..\\data\\documents\\lower_gemini_llm_info.txt\n",
      "Chunk 1: lmm is an abbreviation that stands for **large language model**.\n",
      "it is a type of **artificial intelligence (ai)** program that is trained on a **massive amount of text data** (hence the word \"large\"). this extensive training allows the model to:\n",
      "* **understand** human language (like text you input).\n",
      "\n",
      "----------------------\n",
      "Chunk 2: * **understand** human language (like text you input).\n",
      "* **generate** human-like text (like answers, articles, summaries, and code).\n",
      "### ðŸ”‘ key characteristics\n",
      "\n",
      "----------------------\n",
      "Chunk 3: ### ðŸ”‘ key characteristics\n",
      "* **scale and capacity:** llms are characterized by their immense size, often containing billions or even trillions of **parameters**. this size allows them to capture intricate patterns and nuances in language.\n",
      "\n",
      "----------------------\n",
      "Chunk 4: * **transformer architecture:** most modern llms are built on a neural network architecture called a **transformer**, which is highly effective at tracking relationships and context across long sequences of text.\n",
      "\n",
      "----------------------\n",
      "Chunk 5: * **core function:** at a fundamental level, an llm works by being very good at **predicting the next word** in a sequence, which allows it to generate coherent and contextually relevant text.\n",
      "### ðŸ’¡ common applications\n",
      "llms power many of the advanced ai tools you hear about today. they are used for:\n",
      "\n",
      "----------------------\n",
      "Chunk 6: llms power many of the advanced ai tools you hear about today. they are used for:\n",
      "* **conversational ai/chatbots:** like the one you are interacting with now.\n",
      "* **content generation:** drafting emails, writing articles, creating marketing copy.\n",
      "\n",
      "----------------------\n",
      "Chunk 7: * **content generation:** drafting emails, writing articles, creating marketing copy.\n",
      "* **summarization and translation:** quickly condensing large documents or translating languages.\n",
      "* **code generation:** writing or debugging computer code based on natural language instructions.\n",
      "\n",
      "----------------------\n",
      "Chunk 8: * **code generation:** writing or debugging computer code based on natural language instructions.\n",
      "**examples of llms** include models like openai's gpt series (which powers chatgpt), google's gemini and palm, anthropic's claude, and meta's llama.\n",
      "---\n",
      "\n",
      "----------------------\n",
      "Chunk 9: ---\n",
      "would you like to know more about how llms are trained or see some specific examples of what they can do?\n",
      "\n",
      "----------------------\n",
      "Document: ..\\data\\documents\\orginal_gemini_llm_info.txt\n",
      "Chunk 1: LMM is an abbreviation that stands for **Large Language Model**.\n",
      "It is a type of **Artificial Intelligence (AI)** program that is trained on a **massive amount of text data** (hence the word \"large\"). This extensive training allows the model to:\n",
      "* **Understand** human language (like text you input).\n",
      "\n",
      "----------------------\n",
      "Chunk 2: * **Understand** human language (like text you input).\n",
      "* **Generate** human-like text (like answers, articles, summaries, and code).\n",
      "### ðŸ”‘ Key Characteristics\n",
      "\n",
      "----------------------\n",
      "Chunk 3: ### ðŸ”‘ Key Characteristics\n",
      "* **Scale and Capacity:** LLMs are characterized by their immense size, often containing billions or even trillions of **parameters**. This size allows them to capture intricate patterns and nuances in language.\n",
      "\n",
      "----------------------\n",
      "Chunk 4: * **Transformer Architecture:** Most modern LLMs are built on a neural network architecture called a **Transformer**, which is highly effective at tracking relationships and context across long sequences of text.\n",
      "\n",
      "----------------------\n",
      "Chunk 5: * **Core Function:** At a fundamental level, an LLM works by being very good at **predicting the next word** in a sequence, which allows it to generate coherent and contextually relevant text.\n",
      "### ðŸ’¡ Common Applications\n",
      "LLMs power many of the advanced AI tools you hear about today. They are used for:\n",
      "\n",
      "----------------------\n",
      "Chunk 6: LLMs power many of the advanced AI tools you hear about today. They are used for:\n",
      "* **Conversational AI/Chatbots:** Like the one you are interacting with now.\n",
      "* **Content Generation:** Drafting emails, writing articles, creating marketing copy.\n",
      "\n",
      "----------------------\n",
      "Chunk 7: * **Content Generation:** Drafting emails, writing articles, creating marketing copy.\n",
      "* **Summarization and Translation:** Quickly condensing large documents or translating languages.\n",
      "* **Code Generation:** Writing or debugging computer code based on natural language instructions.\n",
      "\n",
      "----------------------\n",
      "Chunk 8: * **Code Generation:** Writing or debugging computer code based on natural language instructions.\n",
      "**Examples of LLMs** include models like OpenAI's GPT series (which powers ChatGPT), Google's Gemini and PaLM, Anthropic's Claude, and Meta's Llama.\n",
      "---\n",
      "\n",
      "----------------------\n",
      "Chunk 9: ---\n",
      "Would you like to know more about how LLMs are trained or see some specific examples of what they can do?\n",
      "\n",
      "----------------------\n",
      "Document: ..\\data\\documents\\upper_gemini_llm_info.txt\n",
      "Chunk 1: LMM IS AN ABBREVIATION THAT STANDS FOR **LARGE LANGUAGE MODEL**.\n",
      "IT IS A TYPE OF **ARTIFICIAL INTELLIGENCE (AI)** PROGRAM THAT IS TRAINED ON A **MASSIVE AMOUNT OF TEXT DATA** (HENCE THE WORD \"LARGE\"). THIS EXTENSIVE TRAINING ALLOWS THE MODEL TO:\n",
      "* **UNDERSTAND** HUMAN LANGUAGE (LIKE TEXT YOU INPUT).\n",
      "\n",
      "----------------------\n",
      "Chunk 2: * **UNDERSTAND** HUMAN LANGUAGE (LIKE TEXT YOU INPUT).\n",
      "* **GENERATE** HUMAN-LIKE TEXT (LIKE ANSWERS, ARTICLES, SUMMARIES, AND CODE).\n",
      "### ðŸ”‘ KEY CHARACTERISTICS\n",
      "\n",
      "----------------------\n",
      "Chunk 3: ### ðŸ”‘ KEY CHARACTERISTICS\n",
      "* **SCALE AND CAPACITY:** LLMS ARE CHARACTERIZED BY THEIR IMMENSE SIZE, OFTEN CONTAINING BILLIONS OR EVEN TRILLIONS OF **PARAMETERS**. THIS SIZE ALLOWS THEM TO CAPTURE INTRICATE PATTERNS AND NUANCES IN LANGUAGE.\n",
      "\n",
      "----------------------\n",
      "Chunk 4: * **TRANSFORMER ARCHITECTURE:** MOST MODERN LLMS ARE BUILT ON A NEURAL NETWORK ARCHITECTURE CALLED A **TRANSFORMER**, WHICH IS HIGHLY EFFECTIVE AT TRACKING RELATIONSHIPS AND CONTEXT ACROSS LONG SEQUENCES OF TEXT.\n",
      "\n",
      "----------------------\n",
      "Chunk 5: * **CORE FUNCTION:** AT A FUNDAMENTAL LEVEL, AN LLM WORKS BY BEING VERY GOOD AT **PREDICTING THE NEXT WORD** IN A SEQUENCE, WHICH ALLOWS IT TO GENERATE COHERENT AND CONTEXTUALLY RELEVANT TEXT.\n",
      "### ðŸ’¡ COMMON APPLICATIONS\n",
      "LLMS POWER MANY OF THE ADVANCED AI TOOLS YOU HEAR ABOUT TODAY. THEY ARE USED FOR:\n",
      "\n",
      "----------------------\n",
      "Chunk 6: LLMS POWER MANY OF THE ADVANCED AI TOOLS YOU HEAR ABOUT TODAY. THEY ARE USED FOR:\n",
      "* **CONVERSATIONAL AI/CHATBOTS:** LIKE THE ONE YOU ARE INTERACTING WITH NOW.\n",
      "* **CONTENT GENERATION:** DRAFTING EMAILS, WRITING ARTICLES, CREATING MARKETING COPY.\n",
      "\n",
      "----------------------\n",
      "Chunk 7: * **CONTENT GENERATION:** DRAFTING EMAILS, WRITING ARTICLES, CREATING MARKETING COPY.\n",
      "* **SUMMARIZATION AND TRANSLATION:** QUICKLY CONDENSING LARGE DOCUMENTS OR TRANSLATING LANGUAGES.\n",
      "* **CODE GENERATION:** WRITING OR DEBUGGING COMPUTER CODE BASED ON NATURAL LANGUAGE INSTRUCTIONS.\n",
      "\n",
      "----------------------\n",
      "Chunk 8: * **CODE GENERATION:** WRITING OR DEBUGGING COMPUTER CODE BASED ON NATURAL LANGUAGE INSTRUCTIONS.\n",
      "**EXAMPLES OF LLMS** INCLUDE MODELS LIKE OPENAI'S GPT SERIES (WHICH POWERS CHATGPT), GOOGLE'S GEMINI AND PALM, ANTHROPIC'S CLAUDE, AND META'S LLAMA.\n",
      "---\n",
      "\n",
      "----------------------\n",
      "Chunk 9: ---\n",
      "WOULD YOU LIKE TO KNOW MORE ABOUT HOW LLMS ARE TRAINED OR SEE SOME SPECIFIC EXAMPLES OF WHAT THEY CAN DO?\n",
      "\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "path = '../data/documents'\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    Path(path),\n",
    "    glob='**/*.txt',\n",
    "    loader_cls = TextLoader,\n",
    "    loader_kwargs = {'encoding': 'utf8'}\n",
    ")\n",
    "\n",
    "docs = dir_loader.load()\n",
    "\n",
    "for item in docs:\n",
    "    if item.metadata['source'].endswith('.txt'):\n",
    "\n",
    "        text_spliter = CharacterTextSplitter(\n",
    "            separator = '\\n',\n",
    "            chunk_size = 300,\n",
    "            chunk_overlap  = 100,\n",
    "            length_function = len\n",
    "        )\n",
    "\n",
    "        chunks = text_spliter.split_text(item.page_content)\n",
    "        print(f\"Document: {item.metadata['source']}\")\n",
    "        for i,item in enumerate(chunks):\n",
    "            print(f\"Chunk {i+1}: {item}\\n\") \n",
    "            print('----------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ETL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
